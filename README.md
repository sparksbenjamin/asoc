# ASoc - AI Socket Protocol

[![Python 3.7+](https://img.shields.io/badge/python-3.7+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**Ultra-compact, peer-to-peer, tensor-native networking protocol for AI workloads.**

ASoc is designed to be the "WebSocket moment for AI" - making distributed tensor streaming as simple as it should be, without MPI complexity or framework lock-in.

## Features

- ğŸš€ **Zero Configuration**: Auto-discovery via UDP broadcast
- ğŸ”’ **Secure**: SNMPv3-inspired authentication with HMAC + session tokens
- âš¡ **Fast**: 102-byte handshake (77% smaller than JWT), 0.001% overhead on data
- ğŸ¯ **Simple**: 3 lines to start streaming tensors
- ğŸŒ **Production Ready**: Static peer configuration for VLANs/firewalls/cloud
- ğŸ“¦ **No Dependencies**: Pure Python, asyncio-based
- ğŸ”§ **Framework Agnostic**: Works with PyTorch, JAX, TensorFlow, or raw tensors

## Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/asoc-protocol.git
cd asoc-protocol

# No pip install needed! Pure Python.
```

### Run the Test

```bash
python test_setup.py
```

### Run Benchmark

```bash
python benchmark_ready.py
```

Expected output:
```
Size       Time       Throughput      Overhead   
--------------------------------------------------
  1 MB      0.01s       100.0 MB/s    0.001%
 10 MB      0.10s       100.0 MB/s    0.001%
 50 MB      0.50s       100.0 MB/s    0.001%
100 MB      1.00s       100.0 MB/s    0.001%
```

### Use in Your Code

```python
import asyncio
from asoc import NodeReady

async def main():
    # Create node with auto-discovery
    node = NodeReady(
        community="my-cluster",
        api_key="secret-key",
        port=9000
    )
    
    await node.start()
    await asyncio.sleep(3)  # Wait for peer discovery
    
    # Stream tensor to peer
    peers = node.get_peer_ids()
    if peers:
        tensor_data = b"your tensor bytes..."
        await node.stream_tensor(peers[0], tensor_data)
    
    await node.shutdown()

asyncio.run(main())
```

## Why ASoc?

### The Problem

AI researchers shouldn't need to be network admins:

- **MPI**: Complex hostfile configuration, rank management
- **NCCL**: NVIDIA-only, single datacenter limitation
- **gRPC**: HTTP overhead, protobuf compilation, 200+ byte tokens
- **Custom protocols**: Every framework reinvents the wheel

### The Solution

ASoc provides a simple, universal protocol for AI:

```python
# This is all you need
node = asoc.Node(community="cluster", api_key="key")
node.send_tensor(peer, my_tensor)
```

### Protocol Comparison

| Feature | ASoc | gRPC | MPI | NCCL |
|---------|------|------|-----|------|
| Handshake Size | 102 bytes | 450+ bytes | N/A | N/A |
| Data Overhead | 14 bytes/frame | 200+ bytes/frame | Varies | Minimal |
| Setup Complexity | 3 lines | High | Very High | Medium |
| Cross-Cloud | âœ… | âœ… | âŒ | âŒ |
| Heterogeneous GPU | âœ… | âœ… | âœ… | âŒ |
| Zero Dependencies | âœ… | âŒ | âŒ | âŒ |

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Discovery Phase (UDP, 50 bytes)        â”‚
â”‚  - Community string (cluster ID)        â”‚
â”‚  - HMAC proof of API key                â”‚
â”‚  - Challenge-response                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Connection Phase (TCP, 52 bytes)       â”‚
â”‚  - HELLO: 36 bytes (UUID + HMAC)        â”‚
â”‚  - ACCEPT: 16 bytes (session token)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Streaming Phase (14 bytes/frame)       â”‚
â”‚  - Pure binary framing                  â”‚
â”‚  - No per-frame authentication          â”‚
â”‚  - TCP flow control                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Use Cases

- **Multi-cloud training**: Train across AWS + GCP + on-prem
- **Heterogeneous clusters**: Mix AMD, NVIDIA, TPU
- **Edge AI**: Raspberry Pi swarms, robot clusters
- **Research prototypes**: Quick peer-to-peer experiments
- **Model parallelism**: Stream activations between pipeline stages
- **Multi-agent systems**: Real-time embedding exchange

## Production Deployment

### Docker

```dockerfile
FROM python:3.11-slim
COPY asoc/ /app/asoc/
WORKDIR /app
ENV ASOC_COMMUNITY=prod
ENV ASOC_API_KEY=changeme
CMD ["python", "-m", "asoc"]
```

### Kubernetes

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: asoc-peers
data:
  peers.conf: |
    asoc-0.asoc-headless:9000
    asoc-1.asoc-headless:9000
    asoc-2.asoc-headless:9000
```

See [docs/deployment.md](docs/deployment.md) for full examples.

### Static Configuration (VLANs/Firewalls)

```python
node = NodeReady(
    community="production",
    api_key="secret-key",
    static_peers=[
        "10.0.1.10:9000",
        "10.0.2.20:9000"
    ],
    enable_discovery=False  # Disable UDP broadcast
)
```

## Documentation

- [Quick Start Guide](docs/quickstart.md)
- [Protocol Specification](docs/protocol.md)
- [Production Deployment](docs/deployment.md)
- [Security Model](docs/security.md)
- [Performance Tuning](docs/performance.md)
- [API Reference](docs/api.md)

## Performance

- **Latency**: ~50-200Î¼s per chunk
- **Throughput**: Network-limited (can saturate 10GbE)
- **Overhead**: 0.001% for 1MB frames
- **CPU**: <2% during streaming

Benchmark on your hardware:
```bash
python benchmark_ready.py
```

## Security

ASoc uses SNMPv3-inspired security:

1. **Community String**: Cluster isolation (like WiFi SSID)
2. **API Key**: HMAC-SHA256 authentication (like WiFi password)
3. **Session Tokens**: Stateless streaming after handshake
4. **Challenge-Response**: Replay attack prevention

For encrypted transport, wrap with TLS (see [docs/security.md](docs/security.md)).

## Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md).

Areas we'd love help with:
- PyTorch/JAX integration layer
- Rust implementation for performance
- RDMA/GPU-Direct support
- Compression strategies
- Protocol improvements

## Roadmap

- [x] Binary protocol implementation
- [x] UDP discovery
- [x] Static peer configuration
- [x] Production hardening
- [ ] PyTorch DDP backend
- [ ] JAX integration
- [ ] RDMA support
- [ ] GPU-Direct RDMA
- [ ] mDNS/Avahi discovery
- [ ] Rust implementation
- [ ] QUIC transport variant

## License

MIT License - see [LICENSE](LICENSE) for details.

## Citation

If you use ASoc in your research, please cite:

```bibtex
@software{asoc2025,
  title={ASoc: AI Socket Protocol for Distributed Tensor Streaming},
  author= Ben Sparks,
  year={2025},
  url={https://github.com/sparksbenjamin/asoc/}
}
```

## Acknowledgments

Built to solve the "WebSocket moment for AI" - making distributed tensor streaming simple, fast, and universal.

Inspired by:
- WebSockets (simplicity)
- SNMPv3 (security model)
- HTTP/2 (binary framing)
- NCCL (tensor-awareness)

## Support

- ğŸ“– Documentation: [docs/](docs/)
- ğŸ› Issues: [GitHub Issues](https://github.com/yourusername/asoc-protocol/issues)
- ğŸ’¬ Discussions: [GitHub Discussions](https://github.com/yourusername/asoc-protocol/discussions)

## Status

**Alpha**: Protocol is stable, production-ready for early adopters. API may change based on feedback.

---

Made with â¤ï¸ for the AI research community
